{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Assignment 3</h1>\n",
    "<h1> Distributional Semantics and POS Tagging </h1> </center>\n",
    "<hr>\n",
    "<br><b><u>Submitted by:</u><br>\n",
    "Name: Adithya Avvaru<br>\n",
    "Roll No: 20162116\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Latent Symantic Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "def get_unigrams(file_name):\n",
    "    unigrams = {}\n",
    "    with io.open(file_name, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            \n",
    "            # Added to extract only Verbs\n",
    "            # verbs = nltk.pos_tag(tokens)\n",
    "            # tokens = set([x for x,y in verbs if \"VB\" in y]) \n",
    "            \n",
    "            for token in tokens:\n",
    "                token = token.lower()\n",
    "                try:\n",
    "                    unigrams[token]\n",
    "                except:\n",
    "                    unigrams[token] = 0\n",
    "                unigrams[token] += 1\n",
    "                \n",
    "    return unigrams\n",
    "\n",
    "def index_unigrams(unigrams):\n",
    "    new_unigrams = {}\n",
    "    reverse_unigrams = {}\n",
    "    for index, unigram in enumerate(unigrams):\n",
    "        new_unigrams[unigram] = index\n",
    "        reverse_unigrams[index] = unigram\n",
    "    return new_unigrams, reverse_unigrams\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sample_corpus.txt\"\n",
    "unigrams = get_unigrams(file_name)\n",
    "iunigrams,runigrams = index_unigrams(unigrams)\n",
    "unigrams = sorted(unigrams.items(), key = lambda x: x[1], reverse = True )\n",
    "\n",
    "#pprint(unigrams) # Figure out non-stop words\n",
    "dimensions = [x[0] for x in unigrams[100:3100]]\n",
    "idimensions = {x: index for index, x in enumerate(dimensions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def populate_cmatrix(file_name,iunigrams, dimensions, window, leftonly, rightonly):\n",
    "    e = 0\n",
    "    s = 0\n",
    "    cmatrix = numpy.memmap(\"lsa.cmatrix\", dtype='float32', mode='w+', shape=(len(unigrams),len(dimensions)))\n",
    "    with open(file_name, encoding='utf-8', errors='ignore') as f:\n",
    "        for index, line in enumerate(f):             \n",
    "            tokens = line.strip().split()\n",
    "            for indexj, token in enumerate(tokens):\n",
    "                token = token.lower()\n",
    "                lcontext = rcontext = \"\"\n",
    "                if leftonly :\n",
    "                    lcontext = tokens[indexj - window:indexj]\n",
    "                else:\n",
    "                    lcontext = []\n",
    "                if rightonly:\n",
    "                    rcontext = tokens[indexj + 1:index + window]\n",
    "                else:\n",
    "                    rcontext = []\n",
    "                context = [tok.lower() for tok in lcontext + rcontext]\n",
    "                \n",
    "                #verbs = nltk.pos_tag(context)\n",
    "                #context = set([x for x,y in verbs if \"VB\" in y]) \n",
    "                \n",
    "                try:\n",
    "                    unigram_index = iunigrams[token]                    \n",
    "                    for d in context:\n",
    "                        #print(nltk.pos_tag([d]))\n",
    "                        \n",
    "                        if d in dimensions:\n",
    "                            j = dimensions[d]\n",
    "                            cmatrix[unigram_index][j] += 1 \n",
    "                            s += 1\n",
    "                except:\n",
    "                    e += 1\n",
    "    #print(e,s)\n",
    "    return cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import *\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistance(twod_cmatrix):\n",
    "    words = [\"boy\",\"sunday\",\"eat\",\"good\",\"slowly\",\"100\"]\n",
    "    for w1 in words:\n",
    "        distance = {}\n",
    "        for w2 in idimensions:\n",
    "            if w1 == w2:\n",
    "                continue\n",
    "            id1 = iunigrams[w1]\n",
    "            id2 = iunigrams[w2]\n",
    "            v1, v2 = twod_cmatrix[id1], twod_cmatrix[id2]\n",
    "            if np.linalg.norm(v2) == 0:\n",
    "                continue\n",
    "            distance[w2] = cosine(v1,v2)\n",
    "        sortedDistance = sorted(distance.items(), key = lambda x : x[1], reverse = False)\n",
    "        \n",
    "        temp = dict((x, y) for x, y in sortedDistance[:10])  # For top 10 elements\n",
    "        \n",
    "        print(w1)\n",
    "        print(list(temp.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(windowSize=2, noComp=10, leftOnly=True, rightOnly=True):\n",
    "    s = time()\n",
    "    cmatrix = populate_cmatrix(file_name, iunigrams, idimensions, window = windowSize, \\\n",
    "                               leftonly = leftOnly, rightonly = rightOnly)\n",
    "    svd = TruncatedSVD(n_components = noComp, random_state=42)\n",
    "    svd.fit(cmatrix)\n",
    "    twod_cmatrix = svd.transform(cmatrix)\n",
    "    \n",
    "    print(\"Window :\",windowSize,\"; No components :\", noComp, \"; Left only :\", leftOnly, \"; Right only :\", rightOnly)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"Time taken is ---- \", (time()-s))\n",
    "    getDistance(twod_cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window : 2 ; No components : 10 ; Left only : True ; Right only : True\n",
      "-----------------------------------------------------------------------\n",
      "Time taken is ----  59.825199842453\n",
      "boy\n",
      "['supplied', 'miles', 'adobe', 'attend', 'speaker', 'forced', 'leisure', 'nursing', 'birds', 'minutes']\n",
      "sunday\n",
      "['saturday', 'director', 'morning', 'routes', 'ford', '17th', 'seminar', 'evening', 'supported', '1st']\n",
      "eat\n",
      "['saying', 'think', 'me', \"'ve\", 'sit', 'am', 'heavy', 'sorry', \"'re\", \"'ll\"]\n",
      "good\n",
      "['him', 'thanks', 'always', 'though', 'went', 'see', 'take', 'nor', 'often', 'god']\n",
      "slowly\n",
      "['understanding', 'developed', 'brand', 'positive', 'meant', 'parents', 'helpful', 'illness', 'residents', 'clear']\n",
      "100\n",
      "['white', '90', 'column', 'black', '=', 'hotels', 'cm', 'pp', '1000', 'mm']\n"
     ]
    }
   ],
   "source": [
    "run(windowSize=2, noComp=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=10, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=50, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=100, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=200, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=10, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=50, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=100, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=200, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=10, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=50, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=100, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=200, leftOnly=True, rightOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=10, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=50, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=100, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=2, noComp=200, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=10, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=50, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=100, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=5, noComp=200, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=10, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=50, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=100, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(windowSize=10, noComp=200, leftOnly=False, rightOnly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> KMeans Clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cmatrix = populate_cmatrix(file_name, iunigrams, idimensions, window = 5, leftonly=True, rightonly=True)\n",
    "svd = TruncatedSVD(n_components = 100, random_state=42)\n",
    "svd.fit(cmatrix)\n",
    "cmatrix = svd.transform(cmatrix)\n",
    "\n",
    "kmeans = KMeans(n_clusters=100, random_state=0).fit(cmatrix)\n",
    "i=0\n",
    "wordTolabel={}\n",
    "for word in dimensions:\n",
    "    wordTolabel[word] = kmeans.labels_[i]\n",
    "    i=i+1\n",
    "sortedByLabel = sorted(wordTolabel.items(), key = lambda x : x[1], reverse = False)\n",
    "print(sortedByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>OBSERVATIONS:</b>\n",
    "*************\n",
    "The words didnt group into clusters of different POS tags. Majority of words are gouped into cluster 0. When number of clusters are increased, we find a different clustering scheme where words are distributed among other clusters also.\n",
    "The above is the experiment with n_clusters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
